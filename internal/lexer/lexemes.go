// Package lexer provides a lexer for producing tokens of a Fuyu source text.
package lexer

import (
	"github.com/fuyu-lang/fuyu/internal/token"
)

// TODO Docs
func (lexer *Lexer) lexComment() (token.Token, error) {
	// TODO
	panic("Not implemented")
}

// TODO Docs
func (lexer *Lexer) lexSpace() (token.Token, error) {
	// TODO
	panic("Not implemented")
}

// TODO Docs
func (lexer *Lexer) lexNewline() (token.Token, error) {
	// TODO
	panic("Not implemented")
}

// TODO Docs
func (lexer *Lexer) lexWord() (token.Token, error) {
	// TODO Identifiers
	// TODO Keywords
	// TODO Nil
	panic("Not implemented")
}

// TODO Docs
func (lexer *Lexer) lexLiteralBytes() (token.Token, error) {
	// TODO
	panic("Not implemented")
}

// TODO Docs
func (lexer *Lexer) lexLiteralNumber() (token.Token, error) {
	// TODO
	panic("Not implemented")
}

// TODO Docs
func (lexer *Lexer) lexLiteralString() (token.Token, error) {
	// TODO
	panic("Not implemented")
}

// TODO Docs
func (lexer *Lexer) lexLiteralSymbol() (token.Token, error) {
	// TODO
	panic("Not implemented")
}

// TODO Docs
func (lexer *Lexer) lexOperator() (token.Token, error) {
	// TODO
	panic("Not implemented")
}
